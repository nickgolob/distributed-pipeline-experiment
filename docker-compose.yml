services:

  # https://github.com/bitnami/containers/blob/main/bitnami/kafka/README.md#using-a-docker-compose-file
  kafka:
    image: bitnami/kafka:latest
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER

  spark:
    image: bitnami/spark:latest
    container_name: spark
    environment:
      - SPARK_MODE=client
    ports:
      - "8080:8080"  # Spark UI
    volumes:
      - ./kafka-spark-streaming-consumer:/kafka-spark-streaming-consumer
      - ./requirements.txt:/requirements.txt 
    depends_on:
      - kafka
      - postgres
    command: ["spark-submit", "/kafka-spark-streaming-consumer/main.py"]
  
  postgres:
    image: postgres:latest
    container_name: postgres
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=mydatabase
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"

  producer:
    build: ./kafka-producer
    depends_on:
      - kafka
    environment:
      - KAFKA_BROKER=kafka:9092

  reader:
    build: ./redis-postgres-reader
    depends_on:
      - postgres
      - redis
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=mydatabase
      - REDIS_HOST=redis
      - REDIS_PORT=6379


volumes:
  pgdata: