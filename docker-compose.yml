version: '3.8'

services:
  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@1
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
    ports:
      - "9092:9092"

  spark:
    image: bitnami/spark:latest
    container_name: spark
    environment:
      - SPARK_MODE=client
    ports:
      - "8080:8080"  # Spark UI
    volumes:
      - ./consumer:/consumer  # Mount consumer code for Spark job
    depends_on:
      - kafka
      - postgres
    command: ["spark-submit", "/kafka-spark-streaming-consumer/main.py"]
  
  postgres:
    image: postgres:latest
    container_name: postgres
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=mydatabase
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"

  producer:
    build: ./kafka-producer
    depends_on:
      - kafka
    environment:
      - KAFKA_BROKER=kafka:9092

  consumer:
    build: ./kafka-consumer
    depends_on:
      - kafka
      - postgres
    environment:
      - KAFKA_BROKER=kafka:9092
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=mydatabase

  reader:
    build: ./redis-postgres-reader
    depends_on:
      - postgres
      - redis
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=mydatabase
      - REDIS_HOST=redis
      - REDIS_PORT=6379


volumes:
  pgdata: